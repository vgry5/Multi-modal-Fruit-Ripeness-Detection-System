{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65cea8e5-f39c-408e-97e4-0ade9206c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pathlib\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Dense, Reshape, Flatten, Dropout, MaxPooling2D, Conv2D, GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers.legacy import Adam as LegacyAdam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1268a584-9fc3-4ce6-ae0a-7265e85e8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = pathlib.Path('/Users/admin/Downloads/DSGP/Data Set')\n",
    "img_height, img_width = 180,180\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2924b714-f472-4bc4-b8b1-61cb28e1beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "     rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b86fd24-cec5-43ef-acd7-b78ec1a76660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10160 files belonging to 3 classes.\n",
      "Using 8128 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 19:58:41.615982: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-01-22 19:58:41.616012: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-01-22 19:58:41.616020: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-01-22 19:58:41.616064: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-22 19:58:41.616084: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df521b4e-5d3b-49a0-8e87-7b8aeddcc184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a909475-e281-4781-acb9-3f5d97dbf471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_data_augmentation(x, y):\n",
    "    x_augmented = tf.py_function(data_augmentation.flow, [x], tf.float32)\n",
    "    return x_augmented, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b951b0b9-35d3-4a72-a5f8-bc0b6f8a01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(apply_data_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f698e5ba-70b7-4257-9f17-eba346553386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Banana', 'Mango', 'Papaya']\n"
     ]
    }
   ],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd9a5060-4512-4dd7-ba8c-532ce638a607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10160 files belonging to 3 classes.\n",
      "Using 2032 files for validation.\n"
     ]
    }
   ],
   "source": [
    "vali_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d850a114-5f69-4dd4-b544-bb9275709e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model = Sequential()\n",
    "\n",
    "pretrained_m =tf.keras.applications.EfficientNetB7(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(180,180,3),\n",
    "    pooling=None,\n",
    "    classes=3,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "for layer in pretrained_m.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "efficientnet_model.add(pretrained_m)\n",
    "efficientnet_model.add(BatchNormalization())\n",
    "efficientnet_model.add(GlobalAveragePooling2D())\n",
    "efficientnet_model.add(Dense(64, activation='relu'))\n",
    "efficientnet_model.add(Flatten())\n",
    "efficientnet_model.add(Dense(256, activation='relu'))\n",
    "efficientnet_model.add(Dropout(0.2))\n",
    "efficientnet_model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd0a4de0-450b-497e-a35e-2f26b806ceba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb7 (Functional  (None, 6, 6, 2560)        64097687  \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 6, 6, 2560)        10240     \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " module_wrapper (ModuleWrap  (None, 2560)              0         \n",
      " per)                                                            \n",
      "                                                                 \n",
      " module_wrapper_1 (ModuleWr  (None, 64)                163904    \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_2 (ModuleWr  (None, 64)                0         \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_3 (ModuleWr  (None, 256)               16640     \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_4 (ModuleWr  (None, 256)               0         \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_5 (ModuleWr  (None, 3)                 771       \n",
      " apper)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64289242 (245.24 MB)\n",
      "Trainable params: 186435 (728.26 KB)\n",
      "Non-trainable params: 64102807 (244.53 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "efficientnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b570165-92d7-47de-aafc-e37a88a41c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model.compile(optimizer=LegacyAdam(learning_rate=0.01),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4bd93c-e9f4-4f33-8da5-dbb2fcc7b231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 19:59:01.559110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "history = efficientnet_model.fit(\n",
    "    train_ds,\n",
    "    validation_data = vali_ds,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c4511-b6dd-4df0-9560-f34fdab7c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.axis(ymin=0.4,ymax=2)\n",
    "plt.grid()\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0228af-b46b-411b-966e-4a96ba458697",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7eb6f-6345-49b5-93c7-2ae3e169bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image=cv2.imread('/Users/admin/Downloads/DSGP/Ripe-Yellow-Mango-500x375.png')\n",
    "image_resized = cv2.resize(image, (img_height, img_width))\n",
    "image=np.expand_dims(image_resized,axis=0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684b3cb-7921-4041-a5ce-a6652bf19d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=efficientnet_model.predict(image)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e344a4-133c-4fd3-abf4-6cc506dfdb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_class = class_names[np.argmax(pred)]\n",
    "print(\"The fruit is a\", output_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
